{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 11:38:29.362521: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-10 11:38:29.362542: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-10 11:38:29.362547: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-10 11:38:29.362609: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-10 11:38:29.362845: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Checks for available GPUs and lists them\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Set TensorFlow to use only the first GPU\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('../datasets/petfinder-adoption-prediction/train/train.csv')\n",
    "test_data = pd.read_csv('../datasets/petfinder-adoption-prediction/test/test.csv')\n",
    "y_train = train_data['Type'].values - 1  # Types to 0 and 1 (cats and dogs)\n",
    "y_test = test_data['Type'].values - 1    # Types to 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, pet_ids, labels, image_dir, batch_size=32, image_size=(224, 224), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.pet_ids = pet_ids\n",
    "        self.labels = labels\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.pet_ids))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.pet_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        pet_ids_temp = [self.pet_ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_image = self.__load_images(pet_ids_temp)\n",
    "        y = self.labels[indexes]\n",
    "\n",
    "        return X_image, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __load_images(self, pet_ids_temp):\n",
    "        'Loads and preprocesses images'\n",
    "        images = np.empty((self.batch_size, *self.image_size, 3))\n",
    "        for i, pet_id in enumerate(pet_ids_temp):\n",
    "            image_path = os.path.join(self.image_dir, f'{pet_id}-1.jpg')\n",
    "            if os.path.exists(image_path):\n",
    "                image = load_img(image_path, target_size=self.image_size)\n",
    "                image = img_to_array(image)\n",
    "                images[i,] = preprocess_input(image)\n",
    "            else:\n",
    "                # If the image file does not exist, use a zero array as a placeholder\n",
    "                images[i,] = np.zeros((*self.image_size, 3))\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN-only model\n",
    "def build_cnn_model(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)  # Output layer for two classes (cat or dog)\n",
    "    cnn_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:  # Optionally, freeze layers\n",
    "        layer.trainable = False\n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = build_cnn_model((224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Initialize data generators\n",
    "train_generator = DataGenerator(\n",
    "    pet_ids=train_data['PetID'],\n",
    "    labels=y_train,\n",
    "    image_dir='../datasets/petfinder-adoption-prediction/train_images/',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    pet_ids=test_data['PetID'],\n",
    "    labels=y_test,\n",
    "    image_dir='../datasets/petfinder-adoption-prediction/test_images/',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 11:38:30.672183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 180s 383ms/step - loss: 0.2679 - accuracy: 0.9278 - val_loss: 0.1966 - val_accuracy: 0.9448\n",
      "Epoch 2/2\n",
      "468/468 [==============================] - 231s 495ms/step - loss: 0.1458 - accuracy: 0.9519 - val_loss: 0.1683 - val_accuracy: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c5061290>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "cnn_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy per epoch\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
