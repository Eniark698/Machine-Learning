{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 12:11:39.316383: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-04 12:11:39.316399: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-04 12:11:39.316405: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-04 12:11:39.316431: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-04 12:11:39.316445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Checks for available GPUs and lists them\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Set TensorFlow to use only the first GPU\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Reshape data for SVD\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Apply SVD\n",
    "n_components = 50\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "x_train_svd = svd.fit_transform(x_train_flat)\n",
    "x_test_svd = svd.transform(x_test_flat)\n",
    "\n",
    "# Reshape data back for CNN input\n",
    "# Adjusted reshape for the SVD output\n",
    "x_train_svd = x_train_svd.reshape(x_train.shape[0], n_components, 1, 1)\n",
    "x_test_svd = x_test_svd.reshape(x_test.shape[0], n_components, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "# Model with L2 regularization and adjusted architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    Flatten(input_shape=(n_components, 1, 1)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),  # L2 regularization\n",
    "    Dropout(0.3),  # Increased dropout rate\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),   # L2 regularization\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a lower initial learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1500 [..............................] - ETA: 10:02 - loss: 3.1992 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 12:11:49.768324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-01-04 12:11:49.796653: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 18s 12ms/step - loss: 1.3622 - accuracy: 0.6267 - val_loss: 0.6439 - val_accuracy: 0.8723\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 0.6815 - accuracy: 0.8422 - val_loss: 0.5303 - val_accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 0.5983 - accuracy: 0.8679 - val_loss: 0.4982 - val_accuracy: 0.9010\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 17s 12ms/step - loss: 0.5656 - accuracy: 0.8771 - val_loss: 0.4859 - val_accuracy: 0.9029\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.5533 - accuracy: 0.8816 - val_loss: 0.4802 - val_accuracy: 0.9056\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.5483 - accuracy: 0.8826 - val_loss: 0.4822 - val_accuracy: 0.9049\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.5512 - accuracy: 0.8822 - val_loss: 0.4845 - val_accuracy: 0.9067\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.5551 - accuracy: 0.8841 - val_loss: 0.4920 - val_accuracy: 0.9058\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4894 - accuracy: 0.9066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4894384741783142, 0.9065999984741211]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with early stopping\n",
    "model.fit(x_train_svd, y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "model.evaluate(x_test_svd, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
