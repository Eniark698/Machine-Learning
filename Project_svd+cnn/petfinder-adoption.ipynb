{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:05:16.122687: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-04 19:05:16.122703: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-04 19:05:16.122706: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-04 19:05:16.123025: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-04 19:05:16.123315: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Checks for available GPUs and lists them\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Set TensorFlow to use only the first GPU\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load structured data\n",
    "train_data = pd.read_csv('../datasets/petfinder-adoption-prediction/train/train.csv')\n",
    "test_data = pd.read_csv('../datasets/petfinder-adoption-prediction/test/test.csv')\n",
    "\n",
    "# Drop non-numeric and non-relevant columns\n",
    "columns_to_drop = ['Name', 'RescuerID', 'Description', 'PetID']\n",
    "train_data_numeric = train_data.drop(columns=columns_to_drop)\n",
    "test_data_numeric = test_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convert categorical columns to dummy variables\n",
    "train_data_preprocessed = pd.get_dummies(train_data_numeric, drop_first=True)\n",
    "test_data_preprocessed = pd.get_dummies(test_data_numeric, drop_first=True)\n",
    "\n",
    "# Extract features and target variable for training and testing\n",
    "y_train = train_data_preprocessed['Type'].values - 1  # Types to 0 and 1\n",
    "y_test = test_data_preprocessed['Type'].values - 1  # Types to 0 and 1\n",
    "X_train_structured = train_data_preprocessed.drop(columns=['Type', 'AdoptionSpeed'])\n",
    "X_test_structured = test_data_preprocessed.drop(columns=['Type'])\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_structured_scaled = scaler.fit_transform(X_train_structured)\n",
    "X_test_structured_scaled = scaler.transform(X_test_structured)\n",
    "\n",
    "# Apply SVD\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "X_train_svd = svd.fit_transform(X_train_structured_scaled)\n",
    "X_test_svd = svd.transform(X_test_structured_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, pet_ids, structured_data, labels, image_dir, batch_size=32, image_size=(224, 224), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.pet_ids = pet_ids\n",
    "        self.structured_data = structured_data\n",
    "        self.labels = labels\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.pet_ids))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.pet_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        pet_ids_temp = [self.pet_ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_image = self.__load_images(pet_ids_temp)\n",
    "        X_structured = self.structured_data[indexes]\n",
    "        y = self.labels[indexes]\n",
    "\n",
    "        return [X_image, X_structured], y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __load_images(self, pet_ids_temp):\n",
    "        'Loads and preprocesses images'\n",
    "        images = np.empty((self.batch_size, *self.image_size, 3))\n",
    "        for i, pet_id in enumerate(pet_ids_temp):\n",
    "            image_path = os.path.join(self.image_dir, f'{pet_id}-1.jpg')\n",
    "            if os.path.exists(image_path):\n",
    "                image = load_img(image_path, target_size=self.image_size)\n",
    "                image = img_to_array(image)\n",
    "                images[i,] = preprocess_input(image)\n",
    "            else:\n",
    "                # If the image file does not exist, use a zero array as a placeholder\n",
    "                images[i,] = np.zeros((*self.image_size, 3))\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs=base_model.input, outputs=x)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return cnn_model\n",
    "\n",
    "cnn_model = build_cnn_model((224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "# Assuming the SVD output size is 10\n",
    "structured_input = Input(shape=(10,))\n",
    "cnn_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Get features from both models\n",
    "structured_features = Dense(256, activation='relu')(structured_input)\n",
    "cnn_features = cnn_model(cnn_input)\n",
    "\n",
    "# Combine features from CNN and SVD\n",
    "combined_features = Concatenate()([cnn_features, structured_features])\n",
    "combined_features = Dense(512, activation='relu')(combined_features)\n",
    "predictions = Dense(2, activation='softmax')(combined_features)\n",
    "\n",
    "# Complete model\n",
    "model = Model(inputs=[cnn_input, structured_input], outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "468/468 [==============================] - 195s 415ms/step - loss: 0.4239 - accuracy: 0.9460 - val_loss: 0.2461 - val_accuracy: 0.9599\n",
      "Epoch 2/2\n",
      "468/468 [==============================] - 286s 610ms/step - loss: 0.2905 - accuracy: 0.9526 - val_loss: 0.2888 - val_accuracy: 0.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f9387490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Initialize data generators\n",
    "train_generator = DataGenerator(\n",
    "    pet_ids=train_data['PetID'],\n",
    "    structured_data=X_train_svd,\n",
    "    labels=y_train,\n",
    "    image_dir='../datasets/petfinder-adoption-prediction/train_images/',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Assuming you've split your test data into validation set\n",
    "validation_generator = DataGenerator(\n",
    "    pet_ids=test_data['PetID'],\n",
    "    structured_data=X_test_svd,\n",
    "    labels=y_test,\n",
    "    image_dir='../datasets/petfinder-adoption-prediction/test_images//',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=2\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
